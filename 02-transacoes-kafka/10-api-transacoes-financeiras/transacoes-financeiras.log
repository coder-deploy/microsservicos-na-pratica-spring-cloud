2019-07-25 16:36:23.645 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:36:23.646 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:36:23.664  INFO 1504 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 16:36:24.541  INFO 1504 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=30024cf2-f305-3a40-8433-3e6e569b2c09
2019-07-25 16:36:24.547  INFO 1504 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 16:36:24.553  INFO 1504 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 16:36:24.558  INFO 1504 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 16:36:24.607  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$c21f74a4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.652  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.672  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$595f1e50] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.682  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$34f12970] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.693  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$6dd8d23d] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.698  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:24.711  INFO 1504 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$a87661e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:36:25.050  INFO 1504 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 16:36:25.076  INFO 1504 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 16:36:25.077  INFO 1504 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 16:36:26.137  INFO 1504 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 16:36:26.138  INFO 1504 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2461 ms
2019-07-25 16:36:26.502  WARN 1504 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 16:36:26.503  INFO 1504 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 16:36:26.507  WARN 1504 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 16:36:26.508  INFO 1504 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 16:36:26.730  INFO 1504 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 16:36:27.868  INFO 1504 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 16:36:28.086  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 16:36:28.162  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-in
2019-07-25 16:36:28.209  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 16:36:28.218  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 16:36:28.236  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 16:36:28.268  INFO 1504 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 16:36:28.269  INFO 1504 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 16:36:28.269  INFO 1504 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 16:36:28.595 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:36:28.595 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:36:28.986 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:36:28.986 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:36:29.378 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:36:29.378 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:36:29.722 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:36:29.722 ERROR 1504 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:36:29.761  INFO 1504 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 16:36:29.762  INFO 1504 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 16:36:29.802  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:29.802  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:30.917  INFO 1504 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 16:36:30.936  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:30.937  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:30.945  INFO 1504 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:36:30.948  INFO 1504 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 16:36:30.959  INFO 1504 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 16:36:30.970  INFO 1504 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 16:36:31.005  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 16:36:31.402  INFO 1504 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 16:36:31.402  INFO 1504 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 16:36:31.509  INFO 1504 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 16:36:31.509  INFO 1504 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 16:36:31.690  INFO 1504 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 16:36:31.894  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 16:36:31.894  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 16:36:31.894  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 16:36:31.894  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 16:36:31.894  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 16:36:31.895  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 16:36:31.895  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 16:36:32.050  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 16:36:32.053  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 16:36:32.055  INFO 1504 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 16:36:32.058  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564083392057 with initial instances count: 1
2019-07-25 16:36:32.060  INFO 1504 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 16:36:32.061  INFO 1504 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564083392061, current=UP, previous=STARTING]
2019-07-25 16:36:32.064  INFO 1504 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 16:36:32.080  INFO 1504 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 16:36:32.084  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:32.084  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:32.106  INFO 1504 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 16:36:32.112  INFO 1504 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-07-25 16:36:32.131  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:32.131  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:32.138  INFO 1504 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:36:32.157  INFO 1504 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors
2019-07-25 16:36:32.234  INFO 1504 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'application-1.transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors' has 1 subscriber(s).
2019-07-25 16:36:32.235  INFO 1504 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'application-1.transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors' has 0 subscriber(s).
2019-07-25 16:36:32.235  INFO 1504 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'application-1.transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors' has 1 subscriber(s).
2019-07-25 16:36:32.235  INFO 1504 --- [main] o.s.c.stream.binder.BinderErrorChannel   : Channel 'application-1.transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors' has 2 subscriber(s).
2019-07-25 16:36:32.242  INFO 1504 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-07-25 16:36:32.245  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:32.246  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:32.250  INFO 1504 --- [main] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:36:32.257  INFO 1504 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	auto.commit.interval.ms = 100
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2019-07-25 16:36:32.261  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:36:32.261  INFO 1504 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:36:32.263  INFO 1504 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2019-07-25 16:36:32.267  INFO 1504 --- [main] s.i.k.i.KafkaMessageDrivenChannelAdapter : started org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@11148dc2
2019-07-25 16:36:32.274  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:36:32.283  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] Discovered group coordinator DESKTOP-UCD5TPH:9092 (id: 2147483647 rack: null)
2019-07-25 16:36:32.286  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] Revoking previously assigned partitions []
2019-07-25 16:36:32.286  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$1  : partitions revoked: []
2019-07-25 16:36:32.287  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] (Re-)joining group
2019-07-25 16:36:32.295  INFO 1504 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 16:36:32.296  INFO 1504 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 16:36:32.298  INFO 1504 --- [main] com.coder.deploy.Application             : Started Application in 10.157 seconds (JVM running for 11.2)
2019-07-25 16:36:32.549  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] Successfully joined group with generation 1
2019-07-25 16:36:32.552  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] Setting newly assigned partitions [transacoes-0]
2019-07-25 16:36:32.578  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.a.k.c.consumer.internals.Fetcher       : [Consumer clientId=consumer-3, groupId=anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480] Resetting offset for partition transacoes-0 to offset 0.
2019-07-25 16:36:32.602  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.c.s.b.k.KafkaMessageChannelBinder$1  : partitions assigned: [transacoes-0]
2019-07-25 16:41:31.898  INFO 1504 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 16:44:28.212  INFO 1504 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 16:44:28.213  INFO 1504 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 16:44:28.223  INFO 1504 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2019-07-25 16:44:28.565  INFO 1504 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 16:44:28.570  INFO 1504 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:44:28.571  INFO 1504 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:44:28.576  INFO 1504 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:44:31.898 ERROR 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.integration.handler.LoggingHandler   : org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'application-1.kafka-send-in'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[52], headers={kafka_offset=0, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564083868580}], failedMessage=GenericMessage [payload=byte[52], headers={kafka_offset=0, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564083868580}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:453)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:401)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:205)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:369)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$400(KafkaMessageDrivenChannelAdapter.java:74)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:402)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:120)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:211)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:114)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:40)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1275)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1258)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1219)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1200)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1120)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:935)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:751)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[52], headers={kafka_offset=0, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564083868580}]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:138)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:105)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:73)
	... 27 more

2019-07-25 16:44:31.903 ERROR 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.kafka.listener.LoggingErrorHandler   : Error while processing: ConsumerRecord(topic = transacoes, partition = 0, offset = 0, CreateTime = 1564083868580, serialized key size = -1, serialized value size = 52, headers = RecordHeaders(headers = [RecordHeader(key = contentType, value = [34, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 47, 106, 115, 111, 110, 34]), RecordHeader(key = spring_json_header_types, value = [123, 34, 99, 111, 110, 116, 101, 110, 116, 84, 121, 112, 101, 34, 58, 34, 106, 97, 118, 97, 46, 108, 97, 110, 103, 46, 83, 116, 114, 105, 110, 103, 34, 125])], isReadOnly = false), key = null, value = [B@59b7d1d8)

org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'application-1.kafka-send-in'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[52], headers={kafka_offset=0, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564083868580}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:453) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:401) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:205) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:369) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$400(KafkaMessageDrivenChannelAdapter.java:74) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:402) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:120) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) ~[spring-retry-1.2.4.RELEASE.jar:na]
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:211) ~[spring-retry-1.2.4.RELEASE.jar:na]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:114) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:40) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1275) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1258) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1219) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1200) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1120) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:935) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:751) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.8.0_221]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.8.0_221]
	at java.lang.Thread.run(Unknown Source) [na:1.8.0_221]
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:138) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:105) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:73) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 27 common frames omitted

2019-07-25 16:46:31.900  INFO 1504 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 16:47:06.249  WARN 1504 --- [http-nio-6161-exec-5] .w.s.m.s.DefaultHandlerExceptionResolver : Resolved [org.springframework.http.converter.HttpMessageNotReadableException: JSON parse error: Cannot deserialize value of type `com.coder.deploy.enums.Operacao` from String "E": value not one of declared Enum instance names: [SAIDA, ENTRADA]; nested exception is com.fasterxml.jackson.databind.exc.InvalidFormatException: Cannot deserialize value of type `com.coder.deploy.enums.Operacao` from String "E": value not one of declared Enum instance names: [SAIDA, ENTRADA]
 at [Source: (PushbackInputStream); line: 4, column: 17] (through reference chain: com.coder.deploy.domain.Transacao["operacao"])]
2019-07-25 16:47:39.599 ERROR 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.integration.handler.LoggingHandler   : org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'application-1.kafka-send-in'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[67], headers={kafka_offset=1, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564084056593}], failedMessage=GenericMessage [payload=byte[67], headers={kafka_offset=1, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564084056593}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:453)
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:401)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166)
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47)
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109)
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:205)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:369)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$400(KafkaMessageDrivenChannelAdapter.java:74)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431)
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:402)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:120)
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287)
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:211)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:114)
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:40)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1275)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1258)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1219)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1200)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1120)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:935)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:751)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source)
	at java.util.concurrent.FutureTask.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[67], headers={kafka_offset=1, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564084056593}]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:138)
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:105)
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:73)
	... 27 more

2019-07-25 16:47:39.601 ERROR 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.kafka.listener.LoggingErrorHandler   : Error while processing: ConsumerRecord(topic = transacoes, partition = 0, offset = 1, CreateTime = 1564084056593, serialized key size = -1, serialized value size = 67, headers = RecordHeaders(headers = [RecordHeader(key = contentType, value = [34, 97, 112, 112, 108, 105, 99, 97, 116, 105, 111, 110, 47, 106, 115, 111, 110, 34]), RecordHeader(key = spring_json_header_types, value = [123, 34, 99, 111, 110, 116, 101, 110, 116, 84, 121, 112, 101, 34, 58, 34, 106, 97, 118, 97, 46, 108, 97, 110, 103, 46, 83, 116, 114, 105, 110, 103, 34, 125])], isReadOnly = false), key = null, value = [B@5c2a9e9b)

org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'application-1.kafka-send-in'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers, failedMessage=GenericMessage [payload=byte[67], headers={kafka_offset=1, scst_nativeHeadersPresent=true, kafka_consumer=org.apache.kafka.clients.consumer.KafkaConsumer@1695020e, deliveryAttempt=3, kafka_timestampType=CREATE_TIME, kafka_receivedMessageKey=null, kafka_receivedPartitionId=0, contentType=application/json, kafka_receivedTopic=transacoes, kafka_receivedTimestamp=1564084056593}]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:453) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:401) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:187) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:166) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:47) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:109) ~[spring-messaging-5.1.8.RELEASE.jar:5.1.8.RELEASE]
	at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:205) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.sendMessageIfAny(KafkaMessageDrivenChannelAdapter.java:369) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$400(KafkaMessageDrivenChannelAdapter.java:74) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:431) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$IntegrationRecordMessageListener.onMessage(KafkaMessageDrivenChannelAdapter.java:402) ~[spring-integration-kafka-3.1.0.RELEASE.jar:3.1.0.RELEASE]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.lambda$onMessage$0(RetryingMessageListenerAdapter.java:120) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:287) ~[spring-retry-1.2.4.RELEASE.jar:na]
	at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:211) ~[spring-retry-1.2.4.RELEASE.jar:na]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:114) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.adapter.RetryingMessageListenerAdapter.onMessage(RetryingMessageListenerAdapter.java:40) ~[spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:1275) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:1258) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1219) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1200) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1120) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:935) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:751) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700) [spring-kafka-2.2.7.RELEASE.jar:2.2.7.RELEASE]
	at java.util.concurrent.Executors$RunnableAdapter.call(Unknown Source) [na:1.8.0_221]
	at java.util.concurrent.FutureTask.run(Unknown Source) [na:1.8.0_221]
	at java.lang.Thread.run(Unknown Source) [na:1.8.0_221]
Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers
	at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:138) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:105) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:73) ~[spring-integration-core-5.1.6.RELEASE.jar:5.1.6.RELEASE]
	... 27 common frames omitted

2019-07-25 16:51:31.902  INFO 1504 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 16:55:34.154  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 16:55:34.155  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 16:55:34.156  WARN 1504 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564084534156, current=DOWN, previous=UP]
2019-07-25 16:55:34.156  INFO 1504 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 16:55:34.163  INFO 1504 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 16:55:34.168  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2019-07-25 16:55:34.205  INFO 1504 --- [[Ljava.lang.String;@5d3f99d7.container-0-C-1] essageListenerContainer$ListenerConsumer : Consumer stopped
2019-07-25 16:55:34.207  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] s.i.k.i.KafkaMessageDrivenChannelAdapter : stopped org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter@11148dc2
2019-07-25 16:55:34.207  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 16:55:34.207  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 16:55:34.208  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 16:55:34.209  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 16:55:34.212  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 16:55:34.214  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: transacoes.anonymous.1b846c53-98e9-48d2-9e43-7629f4f9e480.errors
2019-07-25 16:55:34.215  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 16:55:34.215  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-in
2019-07-25 16:55:34.215  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 16:55:34.215  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 16:55:34.215  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 16:55:34.216  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 16:55:37.218  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2019-07-25 16:55:37.223  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - deregister  status: 200
2019-07-25 16:55:37.234  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2019-07-25 16:55:37.406  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-07-25 16:55:37.408  INFO 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2019-07-25 16:55:37.657  WARN 1504 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 org.apache.kafka.common.network.Selector.select(Selector.java:691)
 org.apache.kafka.common.network.Selector.poll(Selector.java:411)
 org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
 java.lang.Thread.run(Unknown Source)
2019-07-25 16:55:47.282 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:55:47.283 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:55:47.301  INFO 5468 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 16:55:48.118  INFO 5468 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 16:55:48.125  INFO 5468 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 16:55:48.133  INFO 5468 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 16:55:48.139  INFO 5468 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 16:55:48.197  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$bb86325b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.250  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.268  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$52c5dc07] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.275  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$2e57e727] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.285  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$673f8ff4] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.290  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.301  INFO 5468 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$3ee23d5] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 16:55:48.648  INFO 5468 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 16:55:48.673  INFO 5468 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 16:55:48.674  INFO 5468 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 16:55:49.015  INFO 5468 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 16:55:49.015  INFO 5468 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1703 ms
2019-07-25 16:55:49.409  WARN 5468 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 16:55:49.409  INFO 5468 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 16:55:49.413  WARN 5468 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 16:55:49.414  INFO 5468 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 16:55:49.649  INFO 5468 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 16:55:50.914  INFO 5468 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 16:55:51.160  INFO 5468 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 16:55:51.396  INFO 5468 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 16:55:51.438  INFO 5468 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 16:55:51.469  INFO 5468 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 16:55:51.507  INFO 5468 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 16:55:51.508  INFO 5468 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 16:55:51.508  INFO 5468 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 16:55:51.856 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:55:51.856 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:55:52.244 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:55:52.244 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:55:52.660 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:55:52.660 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:55:53.040 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 16:55:53.040 ERROR 5468 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 16:55:53.083  INFO 5468 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 16:55:53.084  INFO 5468 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 16:55:53.126  INFO 5468 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:55:53.126  INFO 5468 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:55:53.708  INFO 5468 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 16:55:53.728  INFO 5468 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:55:53.729  INFO 5468 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:55:53.735  INFO 5468 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:55:53.738  INFO 5468 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 16:55:53.749  INFO 5468 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 16:55:53.761  INFO 5468 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 16:55:53.795  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 16:55:54.418  INFO 5468 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 16:55:54.420  INFO 5468 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 16:55:54.681  INFO 5468 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 16:55:54.681  INFO 5468 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 16:55:54.875  INFO 5468 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 16:55:55.083  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 16:55:55.084  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 16:55:55.084  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 16:55:55.084  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 16:55:55.084  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 16:55:55.085  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 16:55:55.085  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 16:55:55.278  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 16:55:55.282  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 16:55:55.285  INFO 5468 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 16:55:55.289  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564084555287 with initial instances count: 2
2019-07-25 16:55:55.292  INFO 5468 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 16:55:55.292  INFO 5468 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564084555292, current=UP, previous=STARTING]
2019-07-25 16:55:55.295  INFO 5468 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 16:55:55.325  INFO 5468 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 16:55:55.326  INFO 5468 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 16:55:55.328  INFO 5468 --- [main] com.coder.deploy.Application             : Started Application in 9.503 seconds (JVM running for 10.359)
2019-07-25 16:55:55.336  INFO 5468 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 16:56:34.703  INFO 5468 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 16:56:34.705  INFO 5468 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 16:56:34.714  INFO 5468 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2019-07-25 16:56:34.763  INFO 5468 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 16:56:34.768  INFO 5468 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 16:56:34.768  INFO 5468 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 16:56:34.775  INFO 5468 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 16:58:18.361  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 16:58:18.363  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 16:58:18.364  WARN 5468 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564084698364, current=DOWN, previous=UP]
2019-07-25 16:58:18.364  INFO 5468 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 16:58:18.371  INFO 5468 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 16:58:18.372  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 16:58:18.372  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 16:58:18.372  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 16:58:18.373  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 16:58:18.376  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 16:58:18.378  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 16:58:18.378  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 16:58:18.379  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 16:58:18.379  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 16:58:18.380  INFO 5468 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 17:01:46.643 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:01:46.643 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:01:46.656  INFO 11240 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 17:01:47.354  INFO 11240 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 17:01:47.360  INFO 11240 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 17:01:47.366  INFO 11240 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 17:01:47.371  INFO 11240 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 17:01:47.418  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$ce4b5fa2] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:47.464  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.286  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$658b094e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.294  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$411d146e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.303  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$7a04bd3b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.309  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.319  INFO 11240 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$16b3511c] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:01:48.652  INFO 11240 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 17:01:48.677  INFO 11240 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 17:01:48.678  INFO 11240 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 17:01:48.834  INFO 11240 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 17:01:48.834  INFO 11240 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2168 ms
2019-07-25 17:01:49.227  WARN 11240 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:01:49.228  INFO 11240 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:01:49.232  WARN 11240 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:01:49.232  INFO 11240 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:01:49.433  INFO 11240 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 17:01:51.112  INFO 11240 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 17:01:51.443  INFO 11240 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 17:01:51.523  INFO 11240 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 17:01:51.541  INFO 11240 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 17:01:51.594  INFO 11240 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 17:01:51.628  INFO 11240 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 17:01:51.628  INFO 11240 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 17:01:51.629  INFO 11240 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 17:01:51.974 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:01:51.974 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:01:52.395 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:01:52.395 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:01:52.792 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:01:52.792 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:01:53.141 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:01:53.142 ERROR 11240 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:01:53.180  INFO 11240 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 17:01:53.181  INFO 11240 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 17:01:53.217  INFO 11240 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:01:53.217  INFO 11240 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:01:53.354  INFO 11240 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:01:53.372  INFO 11240 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:01:53.372  INFO 11240 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:01:53.378  INFO 11240 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:01:53.381  INFO 11240 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 17:01:53.391  INFO 11240 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 17:01:53.402  INFO 11240 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 17:01:53.436  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 17:01:53.833  INFO 11240 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 17:01:53.833  INFO 11240 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 17:01:53.937  INFO 11240 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 17:01:53.937  INFO 11240 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 17:01:54.106  INFO 11240 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:01:54.310  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 17:01:54.311  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 17:01:54.425  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 17:01:54.428  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 17:01:54.430  INFO 11240 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 17:01:54.433  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564084914432 with initial instances count: 0
2019-07-25 17:01:54.436  INFO 11240 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 17:01:54.436  INFO 11240 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564084914436, current=UP, previous=STARTING]
2019-07-25 17:01:54.439  INFO 11240 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 17:01:54.464  INFO 11240 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 17:01:54.465  INFO 11240 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 17:01:54.467  INFO 11240 --- [main] com.coder.deploy.Application             : Started Application in 9.148 seconds (JVM running for 10.145)
2019-07-25 17:01:54.495  INFO 11240 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 17:02:24.430  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Application version is -1: false
2019-07-25 17:02:24.431  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 17:02:24.471  INFO 11240 --- [DiscoveryClient-CacheRefreshExecutor-0] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 17:03:53.456  INFO 11240 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 17:03:53.457  INFO 11240 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 17:03:53.465  INFO 11240 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 8 ms
2019-07-25 17:03:53.690  INFO 11240 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:03:53.696  INFO 11240 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:03:53.696  INFO 11240 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:03:53.702  INFO 11240 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:06:41.198  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 17:06:41.200  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 17:06:41.201  WARN 11240 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564085201201, current=DOWN, previous=UP]
2019-07-25 17:06:41.201  INFO 11240 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 17:06:41.207  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 17:06:41.208  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 17:06:41.208  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 17:06:41.208  INFO 11240 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 17:06:41.209  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 17:06:41.212  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 17:06:41.214  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 17:06:41.214  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 17:06:41.215  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 17:06:41.215  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 17:06:41.215  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 17:06:44.216  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2019-07-25 17:06:44.223  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - deregister  status: 200
2019-07-25 17:06:44.233  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2019-07-25 17:06:44.399  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-07-25 17:06:44.400  INFO 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2019-07-25 17:06:44.405  WARN 11240 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 org.apache.kafka.common.network.Selector.select(Selector.java:691)
 org.apache.kafka.common.network.Selector.poll(Selector.java:411)
 org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
 java.lang.Thread.run(Unknown Source)
2019-07-25 17:07:00.510 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:07:00.510 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:07:00.523  INFO 12848 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 17:07:01.219  INFO 12848 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 17:07:01.559  INFO 12848 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 17:07:01.566  INFO 12848 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 17:07:01.571  INFO 12848 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 17:07:01.618  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$80085572] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.664  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.682  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$1747ff1e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.689  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$f2da0a3e] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.698  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$2bc1b30b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.703  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:01.714  INFO 12848 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$c87046ec] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:07:02.050  INFO 12848 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 17:07:02.073  INFO 12848 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 17:07:02.074  INFO 12848 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 17:07:02.266  INFO 12848 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 17:07:02.266  INFO 12848 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1733 ms
2019-07-25 17:07:02.632  WARN 12848 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:07:02.633  INFO 12848 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:07:02.712  WARN 12848 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:07:02.712  INFO 12848 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:07:02.851  INFO 12848 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 17:07:04.006  INFO 12848 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 17:07:04.245  INFO 12848 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 17:07:04.328  INFO 12848 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 17:07:04.362  INFO 12848 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 17:07:04.379  INFO 12848 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 17:07:04.415  INFO 12848 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 17:07:04.417  INFO 12848 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 17:07:04.417  INFO 12848 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 17:07:04.776 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:07:04.776 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:07:05.161 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:07:05.162 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:07:05.572 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:07:05.572 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:07:05.942 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:07:05.942 ERROR 12848 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:07:05.982  INFO 12848 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 17:07:05.984  INFO 12848 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 17:07:06.027  INFO 12848 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:07:06.027  INFO 12848 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:07:06.189  INFO 12848 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:07:06.207  INFO 12848 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:07:06.207  INFO 12848 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:07:06.214  INFO 12848 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:07:06.217  INFO 12848 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 17:07:06.228  INFO 12848 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 17:07:06.240  INFO 12848 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 17:07:06.276  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 17:07:06.674  INFO 12848 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 17:07:06.675  INFO 12848 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 17:07:06.852  INFO 12848 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 17:07:06.853  INFO 12848 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 17:07:07.038  INFO 12848 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:07:07.251  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 17:07:07.251  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 17:07:07.251  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 17:07:07.251  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 17:07:07.252  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 17:07:07.252  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 17:07:07.252  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 17:07:07.423  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 17:07:07.426  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 17:07:07.428  INFO 12848 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 17:07:07.432  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564085227431 with initial instances count: 2
2019-07-25 17:07:07.435  INFO 12848 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 17:07:07.435  INFO 12848 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564085227435, current=UP, previous=STARTING]
2019-07-25 17:07:07.438  INFO 12848 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 17:07:07.465  INFO 12848 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 17:07:07.466  INFO 12848 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 17:07:07.468  INFO 12848 --- [main] com.coder.deploy.Application             : Started Application in 8.343 seconds (JVM running for 9.212)
2019-07-25 17:07:07.476  INFO 12848 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 17:07:21.615  INFO 12848 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 17:07:21.616  INFO 12848 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 17:07:21.627  INFO 12848 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 11 ms
2019-07-25 17:07:21.687  INFO 12848 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:07:21.692  INFO 12848 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:07:21.692  INFO 12848 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:07:21.699  INFO 12848 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:08:16.742  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 17:08:16.743  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 17:08:16.744  WARN 12848 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564085296744, current=DOWN, previous=UP]
2019-07-25 17:08:16.744  INFO 12848 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 17:08:16.751  INFO 12848 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 17:08:16.751  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 17:08:16.751  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 17:08:16.751  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 17:08:16.753  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 17:08:16.755  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 17:08:16.757  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 17:08:16.757  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 17:08:16.758  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 17:08:16.758  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 17:08:16.758  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 17:08:19.760  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2019-07-25 17:08:19.766  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - deregister  status: 200
2019-07-25 17:08:19.775  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2019-07-25 17:08:19.957  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-07-25 17:08:19.958  INFO 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2019-07-25 17:08:19.963  WARN 12848 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 org.apache.kafka.common.network.Selector.select(Selector.java:691)
 org.apache.kafka.common.network.Selector.poll(Selector.java:411)
 org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
 java.lang.Thread.run(Unknown Source)
2019-07-25 17:08:26.547 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:08:26.548 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:08:26.560  INFO 14688 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 17:08:27.242  INFO 14688 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 17:08:27.248  INFO 14688 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 17:08:27.253  INFO 14688 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 17:08:27.258  INFO 14688 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 17:08:27.304  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$4ad15fb6] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.349  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.367  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$e2110962] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.374  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$bda31482] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.383  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$f68abd4f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.389  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.400  INFO 14688 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$93395130] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 17:08:27.721  INFO 14688 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 17:08:27.745  INFO 14688 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 17:08:27.746  INFO 14688 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 17:08:27.898  INFO 14688 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 17:08:27.899  INFO 14688 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1328 ms
2019-07-25 17:08:28.259  WARN 14688 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:08:28.259  INFO 14688 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:08:28.263  WARN 14688 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 17:08:28.263  INFO 14688 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 17:08:28.463  INFO 14688 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 17:08:29.571  INFO 14688 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 17:08:29.788  INFO 14688 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 17:08:29.863  INFO 14688 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 17:08:29.910  INFO 14688 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 17:08:29.927  INFO 14688 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 17:08:29.959  INFO 14688 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 17:08:29.960  INFO 14688 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 17:08:29.960  INFO 14688 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 17:08:30.289 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:08:30.289 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:08:30.657 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:08:30.657 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:08:31.051 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:08:31.052 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:08:31.396 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 17:08:31.397 ERROR 14688 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 17:08:31.435  INFO 14688 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 17:08:31.436  INFO 14688 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 17:08:31.472  INFO 14688 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:08:31.472  INFO 14688 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:08:31.608  INFO 14688 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:08:31.625  INFO 14688 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:08:31.625  INFO 14688 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:08:31.631  INFO 14688 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:08:31.633  INFO 14688 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 17:08:31.644  INFO 14688 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 17:08:31.656  INFO 14688 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 17:08:31.691  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 17:08:32.080  INFO 14688 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 17:08:32.080  INFO 14688 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 17:08:32.183  INFO 14688 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 17:08:32.183  INFO 14688 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 17:08:32.366  INFO 14688 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:08:32.574  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 17:08:32.575  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 17:08:32.730  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 17:08:32.732  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 17:08:32.734  INFO 14688 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 17:08:32.737  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564085312736 with initial instances count: 2
2019-07-25 17:08:32.740  INFO 14688 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 17:08:32.740  INFO 14688 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564085312740, current=UP, previous=STARTING]
2019-07-25 17:08:32.743  INFO 14688 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 17:08:32.769  INFO 14688 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 17:08:32.770  INFO 14688 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 17:08:32.772  INFO 14688 --- [main] com.coder.deploy.Application             : Started Application in 7.569 seconds (JVM running for 8.458)
2019-07-25 17:08:32.779  INFO 14688 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 17:09:00.335  INFO 14688 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 17:09:00.335  INFO 14688 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 17:09:00.344  INFO 14688 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 8 ms
2019-07-25 17:09:00.392  INFO 14688 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 17:09:00.398  INFO 14688 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 17:09:00.399  INFO 14688 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 17:09:00.405  INFO 14688 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 17:13:32.578  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:18:35.242  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:23:35.245  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:28:35.246  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:33:35.248  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:38:35.251  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:43:35.253  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:48:35.256  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:53:35.258  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 17:58:35.261  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:03:35.264  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:08:35.266  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:13:35.269  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:18:35.271  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:23:35.274  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:28:35.276  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:33:35.278  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:38:35.281  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:43:35.283  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:48:35.286  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:53:35.289  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 18:58:35.291  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:03:35.293  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:08:35.296  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:13:35.298  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:18:35.300  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:23:35.303  INFO 14688 --- [AsyncResolver-bootstrap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:27:41.526  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 19:27:41.537  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 19:27:41.538  WARN 14688 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564093661538, current=DOWN, previous=UP]
2019-07-25 19:27:41.539  INFO 14688 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 19:27:41.547  INFO 14688 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 19:27:41.581  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 19:27:41.582  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 19:27:41.582  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 19:27:41.586  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 19:27:41.619  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 19:27:41.628  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 19:27:41.628  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 19:27:41.628  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 19:27:41.628  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 19:27:41.629  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 19:27:44.631  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2019-07-25 19:27:44.648  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - deregister  status: 200
2019-07-25 19:27:44.669  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2019-07-25 19:27:44.839  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-07-25 19:27:44.842  INFO 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2019-07-25 19:27:46.398  WARN 14688 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 org.apache.kafka.common.network.Selector.select(Selector.java:691)
 org.apache.kafka.common.network.Selector.poll(Selector.java:411)
 org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
 java.lang.Thread.run(Unknown Source)
2019-07-25 19:31:49.442 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:31:49.443 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:31:49.456  INFO 13912 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 19:31:50.240  INFO 13912 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 19:31:50.247  INFO 13912 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 19:31:50.253  INFO 13912 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 19:31:50.258  INFO 13912 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 19:31:50.314  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$34ebd5f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.370  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.397  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$9a8e670b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.411  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$7620722b] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.423  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$af081af8] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.430  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.447  INFO 13912 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$4bb6aed9] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:31:50.854  INFO 13912 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 19:31:50.879  INFO 13912 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 19:31:50.880  INFO 13912 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 19:31:51.060  INFO 13912 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 19:31:51.060  INFO 13912 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1590 ms
2019-07-25 19:31:51.451  WARN 13912 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 19:31:51.452  INFO 13912 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 19:31:51.455  WARN 13912 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 19:31:51.456  INFO 13912 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 19:31:51.681  INFO 13912 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 19:31:52.957  INFO 13912 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 19:31:53.212  INFO 13912 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 19:31:53.234  INFO 13912 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 19:31:53.311  INFO 13912 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 19:31:53.362  INFO 13912 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 19:31:53.409  INFO 13912 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 19:31:53.409  INFO 13912 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 19:31:53.409  INFO 13912 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 19:31:53.800 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:31:53.801 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:31:54.211 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:31:54.211 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:31:54.652 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:31:54.652 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:31:55.028 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:31:55.029 ERROR 13912 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:31:55.075  INFO 13912 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 19:31:55.076  INFO 13912 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 19:31:55.115  INFO 13912 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:31:55.115  INFO 13912 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:31:55.267  INFO 13912 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 19:31:55.286  INFO 13912 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:31:55.286  INFO 13912 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:31:55.292  INFO 13912 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 19:31:55.294  INFO 13912 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 19:31:55.306  INFO 13912 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 19:31:55.318  INFO 13912 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 19:31:55.354  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 19:31:55.802  INFO 13912 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 19:31:55.802  INFO 13912 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 19:31:55.917  INFO 13912 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 19:31:55.917  INFO 13912 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 19:31:56.139  INFO 13912 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 19:31:56.351  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 19:31:56.514  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 19:31:56.517  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 19:31:56.519  INFO 13912 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 19:31:56.523  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564093916521 with initial instances count: 2
2019-07-25 19:31:56.525  INFO 13912 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 19:31:56.526  INFO 13912 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564093916526, current=UP, previous=STARTING]
2019-07-25 19:31:56.529  INFO 13912 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 19:31:56.561  INFO 13912 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 19:31:56.562  INFO 13912 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 19:31:56.564  INFO 13912 --- [main] com.coder.deploy.Application             : Started Application in 8.48 seconds (JVM running for 9.375)
2019-07-25 19:31:56.569  INFO 13912 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 19:32:32.800  INFO 13912 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 19:32:32.801  INFO 13912 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 19:32:32.810  INFO 13912 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2019-07-25 19:32:32.876  INFO 13912 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 19:32:32.882  INFO 13912 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:32:32.882  INFO 13912 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:32:32.889  INFO 13912 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 19:34:13.022  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 19:34:13.023  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 19:34:13.023  WARN 13912 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564094053023, current=DOWN, previous=UP]
2019-07-25 19:34:13.024  INFO 13912 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 19:34:13.030  INFO 13912 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 19:34:13.030  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 19:34:13.031  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 19:34:13.031  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 19:34:13.032  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 19:34:13.034  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 19:34:13.036  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 19:34:13.036  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 19:34:13.037  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 19:34:13.037  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 19:34:13.038  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
2019-07-25 19:34:16.040  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Unregistering ...
2019-07-25 19:34:16.046  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - deregister  status: 200
2019-07-25 19:34:16.055  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Completed shut down of DiscoveryClient
2019-07-25 19:34:16.228  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2019-07-25 19:34:16.229  INFO 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2019-07-25 19:34:16.234  WARN 13912 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [kafka-producer-network-thread | producer-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 org.apache.kafka.common.network.Selector.select(Selector.java:691)
 org.apache.kafka.common.network.Selector.poll(Selector.java:411)
 org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:239)
 org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:163)
 java.lang.Thread.run(Unknown Source)
2019-07-25 19:34:35.462 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:34:35.462 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:34:35.481  INFO 7728 --- [main] com.coder.deploy.Application             : No active profile set, falling back to default profiles: default
2019-07-25 19:34:36.321  INFO 7728 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=8108efd1-60fe-3f71-9bc7-3ecf2d531e32
2019-07-25 19:34:36.328  INFO 7728 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'errorChannel' has been explicitly defined. Therefore, a default PublishSubscribeChannel will be created.
2019-07-25 19:34:36.334  INFO 7728 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created.
2019-07-25 19:34:36.340  INFO 7728 --- [main] faultConfiguringBeanFactoryPostProcessor : No bean named 'integrationHeaderChannelRegistry' has been explicitly defined. Therefore, a default DefaultHeaderChannelRegistry will be created.
2019-07-25 19:34:36.392  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.kafka.annotation.KafkaBootstrapConfiguration' of type [org.springframework.kafka.annotation.KafkaBootstrapConfiguration$$EnhancerBySpringCGLIB$$dd381b66] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.440  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'integrationDisposableAutoCreatedBeans' of type [org.springframework.integration.config.annotation.Disposables] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.459  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.integration.config.IntegrationManagementConfiguration' of type [org.springframework.integration.config.IntegrationManagementConfiguration$$EnhancerBySpringCGLIB$$7477c512] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.469  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration' of type [org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration$IntegrationJmxConfiguration$$EnhancerBySpringCGLIB$$5009d032] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.483  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration' of type [org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration$$EnhancerBySpringCGLIB$$88f178ff] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.489  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'mbeanServer' of type [com.sun.jmx.mbeanserver.JmxMBeanServer] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.502  INFO 7728 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$25a00ce0] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2019-07-25 19:34:36.855  INFO 7728 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 6161 (http)
2019-07-25 19:34:36.881  INFO 7728 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2019-07-25 19:34:36.882  INFO 7728 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.21]
2019-07-25 19:34:37.075  INFO 7728 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2019-07-25 19:34:37.076  INFO 7728 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1583 ms
2019-07-25 19:34:37.478  WARN 7728 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 19:34:37.478  INFO 7728 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 19:34:37.482  WARN 7728 --- [main] c.n.c.sources.URLConfigurationSource     : No URLs will be polled as dynamic configuration sources.
2019-07-25 19:34:37.482  INFO 7728 --- [main] c.n.c.sources.URLConfigurationSource     : To enable URLs as dynamic configuration sources, define System property archaius.configurationSource.additionalUrls or make config.properties available on classpath.
2019-07-25 19:34:37.682  INFO 7728 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2019-07-25 19:34:38.821  INFO 7728 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService 'taskScheduler'
2019-07-25 19:34:39.042  INFO 7728 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel errorChannel
2019-07-25 19:34:39.118  INFO 7728 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel kafka-send-out
2019-07-25 19:34:39.164  INFO 7728 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageChannel nullChannel
2019-07-25 19:34:39.181  INFO 7728 --- [main] o.s.i.monitor.IntegrationMBeanExporter   : Registering MessageHandler errorLogger
2019-07-25 19:34:39.214  INFO 7728 --- [main] o.s.i.endpoint.EventDrivenConsumer       : Adding {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 19:34:39.215  INFO 7728 --- [main] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 1 subscriber(s).
2019-07-25 19:34:39.215  INFO 7728 --- [main] o.s.i.endpoint.EventDrivenConsumer       : started _org.springframework.integration.errorLogger
2019-07-25 19:34:40.153 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:34:40.154 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:34:40.546 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:34:40.546 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:34:40.952 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:34:40.952 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:34:41.303 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level '' for 'null'
2019-07-25 19:34:41.303 ERROR 7728 --- [main] o.s.b.c.l.LoggingApplicationListener     : Cannot set level 'FULL' for 'project.user.UserClient'
2019-07-25 19:34:41.343  INFO 7728 --- [main] o.s.c.s.b.k.p.KafkaTopicProvisioner      : Using kafka topic for outbound: transacoes
2019-07-25 19:34:41.344  INFO 7728 --- [main] o.a.k.clients.admin.AdminClientConfig    : AdminClientConfig values: 
	bootstrap.servers = [localhost:9092]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2019-07-25 19:34:41.382  INFO 7728 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:34:41.382  INFO 7728 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:34:41.524  INFO 7728 --- [main] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 19:34:41.542  INFO 7728 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:34:41.542  INFO 7728 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:34:41.548  INFO 7728 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 19:34:41.550  INFO 7728 --- [main] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2019-07-25 19:34:41.562  INFO 7728 --- [main] o.s.c.s.m.DirectWithAttributesChannel    : Channel 'application-1.kafka-send-out' has 1 subscriber(s).
2019-07-25 19:34:41.574  INFO 7728 --- [main] o.s.c.n.eureka.InstanceInfoFactory       : Setting initial instance status as: STARTING
2019-07-25 19:34:41.608  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Initializing Eureka in region us-east-1
2019-07-25 19:34:41.995  INFO 7728 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON encoding codec LegacyJacksonJson
2019-07-25 19:34:41.995  INFO 7728 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using JSON decoding codec LegacyJacksonJson
2019-07-25 19:34:42.103  INFO 7728 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML encoding codec XStreamXml
2019-07-25 19:34:42.103  INFO 7728 --- [main] c.n.d.provider.DiscoveryJerseyProvider   : Using XML decoding codec XStreamXml
2019-07-25 19:34:42.290  INFO 7728 --- [main] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Disable delta property : false
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Single vip registry refresh property : null
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Force full registry fetch : false
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Application is null : false
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Registered Applications size is zero : true
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Application version is -1: true
2019-07-25 19:34:42.498  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Getting all instance registry info from the eureka server
2019-07-25 19:34:42.666  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : The response status is 200
2019-07-25 19:34:42.669  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Starting heartbeat executor: renew interval is: 30
2019-07-25 19:34:42.671  INFO 7728 --- [main] c.n.discovery.InstanceInfoReplicator     : InstanceInfoReplicator onDemand update allowed rate per min is 4
2019-07-25 19:34:42.674  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Discovery Client initialized at timestamp 1564094082673 with initial instances count: 1
2019-07-25 19:34:42.677  INFO 7728 --- [main] o.s.c.n.e.s.EurekaServiceRegistry        : Registering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status UP
2019-07-25 19:34:42.677  INFO 7728 --- [main] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564094082677, current=UP, previous=STARTING]
2019-07-25 19:34:42.680  INFO 7728 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 19:34:42.706  INFO 7728 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 6161 (http) with context path ''
2019-07-25 19:34:42.707  INFO 7728 --- [main] .s.c.n.e.s.EurekaAutoServiceRegistration : Updating port to 6161
2019-07-25 19:34:42.709  INFO 7728 --- [main] com.coder.deploy.Application             : Started Application in 8.738 seconds (JVM running for 9.681)
2019-07-25 19:34:42.715  INFO 7728 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 19:35:04.165  INFO 7728 --- [http-nio-6161-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2019-07-25 19:35:04.166  INFO 7728 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2019-07-25 19:35:04.175  INFO 7728 --- [http-nio-6161-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2019-07-25 19:35:04.218  INFO 7728 --- [http-nio-6161-exec-2] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2019-07-25 19:35:04.224  INFO 7728 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka version : 2.0.1
2019-07-25 19:35:04.224  INFO 7728 --- [http-nio-6161-exec-2] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId : fa14705e51bd2ce5
2019-07-25 19:35:04.231  INFO 7728 --- [kafka-producer-network-thread | producer-2] org.apache.kafka.clients.Metadata        : Cluster ID: q_0q0AOZRpSm9FJEEZlkxQ
2019-07-25 19:35:30.916  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2019-07-25 19:35:30.918  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.c.n.e.s.EurekaServiceRegistry        : Unregistering application TRANSACOES-FINANCEIRAS-SERVICE with eureka with status DOWN
2019-07-25 19:35:30.918  WARN 7728 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Saw local status change event StatusChangeEvent [timestamp=1564094130918, current=DOWN, previous=UP]
2019-07-25 19:35:30.919  INFO 7728 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161: registering service...
2019-07-25 19:35:30.925  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : Removing {logging-channel-adapter:_org.springframework.integration.errorLogger} as a subscriber to the 'errorChannel' channel
2019-07-25 19:35:30.926  INFO 7728 --- [DiscoveryClient-InstanceInfoReplicator-0] com.netflix.discovery.DiscoveryClient    : DiscoveryClient_TRANSACOES-FINANCEIRAS-SERVICE/DESKTOP-UCD5TPH:TRANSACOES-FINANCEIRAS-SERVICE:6161 - registration status: 204
2019-07-25 19:35:30.926  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.channel.PublishSubscribeChannel    : Channel 'application-1.errorChannel' has 0 subscriber(s).
2019-07-25 19:35:30.926  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.endpoint.EventDrivenConsumer       : stopped _org.springframework.integration.errorLogger
2019-07-25 19:35:30.927  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService 'taskScheduler'
2019-07-25 19:35:30.929  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2019-07-25 19:35:30.931  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: errorChannel
2019-07-25 19:35:30.931  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: kafka-send-out
2019-07-25 19:35:30.932  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: nullChannel
2019-07-25 19:35:30.932  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] o.s.i.monitor.IntegrationMBeanExporter   : Summary on shutdown: _org.springframework.integration.errorLogger.handler
2019-07-25 19:35:30.933  INFO 7728 --- [RMI TCP Connection(2)-127.0.0.1] com.netflix.discovery.DiscoveryClient    : Shutting down DiscoveryClient ...
